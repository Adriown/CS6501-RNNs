{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "In this lab we will experiment with recurrent neural networks. We will build a text generation model that predicts a word given the previous words, and hence will allow us to generate a sentence. This can easily be extended to generating a sentence description for a given input image. RNNs are a useful type of model for predicting sequences or handling sequences of things as inputs. In this lab we will use again Pytorch's nn library.\n",
    "\n",
    "We will also be using the COCO dataset which includes images + textual descriptions (captions) + other annotations. We can browse the dataset here: http://cocodataset.org/#home\n",
    "\n",
    "First, let's import libraries and make sure we have everything properly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, json, string\n",
    "import torch.nn as nn\n",
    "import torch.autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Preprocessing the Text\n",
    "Pytorch comes with a Dataset class for the COCO dataset but I will write my own class here. This class does two important things: 1) Building a vocabulary with the most frequent words, 2) Building utilities to convert a sentence into a list of word ids, and back. We are not going to be using the images for the purposes of the lab but you will use them in the assignment questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac9f3a30c80494a90bc97cc6ef73c31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('Number of training examples: ', 414113)\n",
      "('Number of validation examples: ', 202654)\n",
      "('imgId', 318556)\n",
      "('caption', [5001, 1, 141, 512, 8, 668, 415, 277, 57, 0])\n",
      "('captionString', u'[START] a very clean and well decorated empty bathroom [END]')\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class CocoCaptions(data.Dataset):\n",
    "    # Load annotations in the initialization of the object.\n",
    "    def __init__(self, captionsFile, vocabulary = None):\n",
    "        self.data = json.load(open(captionsFile))\n",
    "        self.imageIds = self.data['images']\n",
    "        self.annotations = self.data['annotations']\n",
    "        \n",
    "        # Build a vocabulary if not provided.\n",
    "        if not vocabulary:\n",
    "            self.build_vocabulary()\n",
    "        else:\n",
    "            self.vocabulary = vocabulary\n",
    "        \n",
    "    # Build a vocabulary using the top 5000 words.\n",
    "    def build_vocabulary(self, vocabularySize = 5000):\n",
    "        # Count words, this will take a while.\n",
    "        word_counter = dict()\n",
    "        for annotation in tqdm(self.annotations, desc = 'Building vocabulary'):\n",
    "            words = word_tokenize(annotation['caption'].lower())\n",
    "            for word in words:\n",
    "                word_counter[word] = word_counter.get(word, 0) + 1\n",
    "                \n",
    "        # Sort the words and find keep only the most frequent words.\n",
    "        sorted_words = sorted(list(word_counter.items()), \n",
    "                              key = lambda x: -x[1])\n",
    "        most_frequent_words = [w for (w, c) in sorted_words[:vocabularySize]]\n",
    "        word2id = {w: (index + 1) for (index, w) in enumerate(most_frequent_words)}\n",
    "        \n",
    "        # Add a special characters for START, END sentence, and UNKnown words.\n",
    "        word2id['[END]'] = 0\n",
    "        word2id['[START]'] = len(word2id)\n",
    "        word2id['UNK'] = len(word2id)\n",
    "        id2word = {index: w for (w, index) in word2id.items()}\n",
    "        self.vocabulary = {'word2id': word2id, 'id2word': id2word}\n",
    "    \n",
    "    # Transform a caption into a list of word ids.\n",
    "    def caption2ids(self, caption):\n",
    "        word2id = self.vocabulary['word2id']\n",
    "        caption_ids = [word2id.get(w, word2id['UNK']) for w in word_tokenize(caption.lower())]\n",
    "        caption_ids.insert(0, word2id['[START]'])\n",
    "        caption_ids.append(word2id['[END]'])\n",
    "        return torch.LongTensor(caption_ids)\n",
    "    \n",
    "    # Transform a list of word ids into a caption.\n",
    "    def ids2caption(self, caption_ids):\n",
    "        id2word = self.vocabulary['id2word']\n",
    "        return string.join([id2word[w] for w in caption_ids], \" \")\n",
    "    \n",
    "    # Return imgId, and a random caption for that image.\n",
    "    def __getitem__(self, index):\n",
    "        annotation = self.annotations[index]\n",
    "        return annotation['image_id'], self.caption2ids(annotation['caption'])\n",
    "    \n",
    "    # Return the number of elements of the dataset.\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "# Let's test the data class.\n",
    "trainData = CocoCaptions('annotations/captions_train2014.json')\n",
    "print('Number of training examples: ', len(trainData))\n",
    "\n",
    "# It would be a mistake to build a vocabulary using the validation set so we reuse.\n",
    "valData = CocoCaptions('annotations/captions_val2014.json', vocabulary = trainData.vocabulary)\n",
    "print('Number of validation examples: ', len(valData))\n",
    "\n",
    "# Print a sample from the training data.\n",
    "imgId, caption = trainData[0]\n",
    "print('imgId', imgId)\n",
    "print('caption', caption.tolist())\n",
    "print('captionString', trainData.ids2caption(caption))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('imgId', 318556)\n",
      "('caption', [5001, 1, 141, 512, 8, 668, 415, 277, 57, 0])\n",
      "('captionString', u'[START] a very clean and well decorated empty bathroom [END]')\n"
     ]
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download()\n",
    "\n",
    "imgId, caption = trainData[0]\n",
    "print('imgId', imgId)\n",
    "print('caption', caption.tolist())\n",
    "print('captionString', trainData.ids2caption(caption))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making a Data Loader that can Handle Sequences.\n",
    "\n",
    "Handling sequences is special when processing batches of inputs because each sequence can have a different length. This makes batching complicated, and different libraries have different ways of handling this which might be easier or harder to deal with. Here we are padding the sequences to the maximum sequence length in a given batch. Additionally pytorch has nice utility functions that require sorting the sequences in a batch from longest to shortest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('imgIds', (147780, 533941, 179914, 367896, 107527, 185719, 182645, 4376, 105976, 438527, 507248, 256651, 75114, 13922, 192494, 202066, 129216, 384750, 13662, 51067, 502593, 308606, 541918, 85945, 507495, 166261, 293311, 19394, 186608, 330139, 123142, 561354, 456528, 230367, 23250, 13802, 21235, 25576, 456136, 80980, 8193, 121530, 30791, 165766, 431178, 79104, 430848, 536494, 72601, 75451, 542312, 29153, 122144, 135163, 274196, 511495, 397388, 66444, 135592, 168627, 515123, 20765, 143900, 263101, 52650, 234649, 8747, 473495, 333433, 418824, 493187, 383934, 243629, 373585, 17170, 272402, 117160, 118934, 522391, 562192, 17580, 80360, 11411, 472089, 247469, 178144, 422050, 132531, 576030, 44286, 127268, 303140, 461799, 52284, 11506, 197780, 391896, 377055, 158099, 27919, 292294, 189020, 403222, 161846, 101552, 84602, 19695, 371301, 314201, 558646, 548088, 19767, 282843, 13016, 239007, 22268, 343765, 418221, 491170, 552876, 575980, 384961, 470811, 381922, 371595, 187576, 314681, 3386))\n",
      "('paddedSequences', torch.Size([27, 128]))\n",
      "('seqLengths', (27, 19, 19, 19, 18, 18, 18, 17, 17, 16, 16, 16, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 10, 10, 10, 10, 10, 10, 10, 10))\n"
     ]
    }
   ],
   "source": [
    "# The batch builder will pack all sequences of different length into a single tensor by \n",
    "# padding shorter sequences with a padding token.\n",
    "def customBatchBuilder(samples):\n",
    "    imgIds, captionSeqs = zip(*samples)\n",
    "    \n",
    "    # Sort sequences based on length.\n",
    "    seqLengths = [len(seq) for seq in captionSeqs]\n",
    "    maxSeqLength = max(seqLengths)\n",
    "    sorted_list = sorted(zip(list(imgIds), captionSeqs, seqLengths), key = lambda x: -x[2])\n",
    "    imgIds, captionSeqs, seqLengths = zip(*sorted_list)\n",
    "    \n",
    "    # Create tensor with padded sequences.\n",
    "    paddedSeqs = torch.LongTensor(len(imgIds), maxSeqLength)\n",
    "    paddedSeqs.fill_(0)\n",
    "    for (i, seq) in enumerate(captionSeqs):\n",
    "        paddedSeqs[i, :len(seq)] = seq\n",
    "    return imgIds, paddedSeqs.t(), seqLengths\n",
    "\n",
    "# Data loaders in pytorch can use a custom batch builder, which we are using here.\n",
    "trainLoader = data.DataLoader(trainData, batch_size = 128, \n",
    "                              shuffle = True, num_workers = 0,\n",
    "                              collate_fn = customBatchBuilder)\n",
    "valLoader = data.DataLoader(valData, batch_size = 128, \n",
    "                            shuffle = False, num_workers = 0,\n",
    "                            collate_fn = customBatchBuilder)\n",
    "\n",
    "# Now let's try using the data loader.\n",
    "index, (imgIds, paddedSeqs, seqLengths) = next(enumerate(trainLoader))\n",
    "print('imgIds', imgIds)\n",
    "print('paddedSequences', paddedSeqs.size())\n",
    "print('seqLengths', seqLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 5001  5001  5001  ...   5001  5001  5001\n",
       "    1    29     1  ...      1    13     1\n",
       "   78    90   144  ...     28   750   178\n",
       "       ...          ⋱          ...       \n",
       " 1073     0     0  ...      0     0     0\n",
       "    2     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.LongTensor of size 27x128]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paddedSeqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 3. Building our model using a Recurrent Neural Network.\n",
    "We will build a model that predicts the next word based on the previous word using a recurrent neural network. Additionally we will be using an Embedding layer which will assign a unique vector to each word. The network will be trained with a softmax + negative log likelihood loss. Similar to classification we will be trying to optimize for the correct word at each time-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are input and output size tensor sizes:\n",
      "('inputs', torch.Size([21, 128]))\n",
      "('outputs', torch.Size([21, 128, 5003]))\n"
     ]
    }
   ],
   "source": [
    "# By now, we should know that pytorch has a functional implementation (as opposed to class version)\n",
    "# of many common layers, which is especially useful for layers that do not have any parameters.\n",
    "# e.g. relu, sigmoid, softmax, etc.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextGeneratorModel(nn.Module):\n",
    "    # The model has three layers: \n",
    "    #    1. An Embedding layer that turns a sequence of word ids into \n",
    "    #       a sequence of vectors of fixed size: embeddingSize.\n",
    "    #    2. An RNN layer that turns the sequence of embedding vectors into \n",
    "    #       a sequence of hiddenStates.\n",
    "    #    3. A classification layer that turns a sequence of hidden states into a \n",
    "    #       sequence of softmax outputs.\n",
    "    def __init__(self, vocabularySize):\n",
    "        super(TextGeneratorModel, self).__init__()\n",
    "        # See documentation for nn.Embedding here:\n",
    "        # http://pytorch.org/docs/master/nn.html#torch.nn.Embedding\n",
    "        self.embedder = nn.Embedding(vocabularySize, 300)\n",
    "        self.rnn = nn.RNN(300, 512, batch_first = False)\n",
    "        self.classifier = nn.Linear(512, vocabularySize)\n",
    "        self.vocabularySize = vocabularySize\n",
    "\n",
    "    # The forward pass makes the sequences go through the three layers defined above.\n",
    "    def forward(self, paddedSeqs, initialHiddenState):\n",
    "        batchSequenceLength = paddedSeqs.size(0)  # 0-dim is sequence-length-dim.\n",
    "        batchSize = paddedSeqs.size(1)  # 1-dim is batch dimension.\n",
    "        \n",
    "        # Transform word ids into an embedding vector.\n",
    "        embeddingVectors = self.embedder(paddedSeqs)\n",
    "        \n",
    "        # Pass the sequence of word embeddings to the RNN.\n",
    "        rnnOutput, finalHiddenState = self.rnn(embeddingVectors, initialHiddenState)\n",
    "        \n",
    "        # Collapse the batch and sequence-length dimensions in order to use nn.Linear.\n",
    "        flatSeqOutput = rnnOutput.view(-1, 512)\n",
    "        predictions = self.classifier(flatSeqOutput)\n",
    "        \n",
    "        # Expand back the batch and sequence-length dimensions and return. \n",
    "        return predictions.view(batchSequenceLength, batchSize, self.vocabularySize), \\\n",
    "               finalHiddenState\n",
    "\n",
    "# Let's test the model on some input batch.\n",
    "vocabularySize = len(trainData.vocabulary['word2id'])\n",
    "model = TextGeneratorModel(vocabularySize)\n",
    "\n",
    "# Create the initial hidden state for the RNN.\n",
    "index, (imgIds, paddedSeqs, seqLengths) = next(enumerate(trainLoader))\n",
    "# h1  --  all 0's\n",
    "initialHiddenState = Variable(torch.Tensor(1, paddedSeqs.size(1), 512).zero_())\n",
    "predictions, _ = model(torch.autograd.Variable(paddedSeqs), initialHiddenState)\n",
    "\n",
    "print('Here are input and output size tensor sizes:')\n",
    "# Inputs are seqLength x batchSize x 1 \n",
    "print('inputs', paddedSeqs.size()) # 10 input sequences.\n",
    "# Outputs are trainData.vocabularyseqLength x batchSize x vocabularySize\n",
    "print('outputs', predictions.size()) # 10 output softmax predictions over our vocabularySize outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling a New Sentence from the Model.\n",
    "\n",
    "The code below uses the RNN network as an RNN cell where we only pass one single input word, and a hidden state vector. Then we keep passing the previously predicted word, and previously predicted hidden state to predict the next word. Since the given model is not trained, it will just output a random sequence of words for now. Ideally, the trained model should also learn when to [END] a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] the barely mother umbrella platters coach partly trees equipment sexy curb belt toys fuzzy underside sniffs cuddling watering pens sprinkles conversation leaping canada turn gnar liberty razor well pine super peacefully frisby swimming hall trash scarves asleep homemade burgundy artwork headband beam deserts tights destination of canopy getting half-pipe forehand raspberries barren coach spray comfortably jug space smaller mark umpire receive airline gathering dragging racer corner here dragon instrument processor lighting protruding rally await enormous hold nude halves napping patrons bedside unloading patties kayak daisies hallway corn coat nuzzling framed biscuit love lightly buy note trekking track caps cob twin leash edible because underside pumpkin much newspapers worked maneuver sure white diner windmill newspapers process vests watch runs tracks drawers pear restroom multi-colored salmon pier sweatshirt legs stationed fruit pesto oxen skiers rows flamingos curious gifts been sunlight couples practice jersey duck car camper into dense peeking accessories turns stripped half pic tide forrest bedroom lots tired distance his burner spread built-in circular cauliflower bump currently backed threw wild bit meals penny rat must sailboat this dash holing surprised colored lips outhouse mini bit channel sticking downtown disgusting facility san mixture zone rug petted mounds pane screens bike seeds aboard unattended candy sweatshirt\n"
     ]
    }
   ],
   "source": [
    "def sample_sentence(model, use_cuda = False):\n",
    "    counter = 0\n",
    "    limit = 200\n",
    "    words = list()\n",
    "\n",
    "    # Setup initial input state, and input word (we use \"the\").\n",
    "    previousWord = torch.LongTensor(1, 1).fill_(trainData.vocabulary['word2id']['the'])\n",
    "    previousHiddenState = torch.autograd.Variable(torch.Tensor(1, 1, 512).zero_())\n",
    "    if use_cuda: previousHiddenState = previousHiddenState.cuda()\n",
    "\n",
    "    while True:\n",
    "        # Predict the next word based on the previous hidden state and previous word.\n",
    "        inputWord = torch.autograd.Variable(previousWord)\n",
    "        if use_cuda: inputWord = inputWord.cuda()\n",
    "        predictions, hiddenState = model(inputWord, previousHiddenState)\n",
    "        nextWordId = np.random.multinomial(1, F.softmax(predictions.squeeze()).data.cpu().numpy(), 1).argmax()\n",
    "        words.append(trainData.vocabulary['id2word'][nextWordId])\n",
    "        # Setup the inputs for the next round.\n",
    "        previousWord.fill_(nextWordId)\n",
    "        previousHiddenState = hiddenState\n",
    "\n",
    "        # Keep adding words until the [END] token is generated.\n",
    "        if nextWordId == trainData.vocabulary['word2id']['[END]'] or counter > limit:\n",
    "            break\n",
    "        counter += 1\n",
    "    \n",
    "    words.insert(0, 'the')\n",
    "    words.insert(0, '[START]')\n",
    "    return string.join(words, \" \")\n",
    "\n",
    "print(sample_sentence(model, use_cuda = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the Model\n",
    "\n",
    "Now that data is pre-processed, we can try training the model. An important part is to define our target labels or ground-truth labels. In this text generation model, we want to predict the next word based on the previous word. So we need to provide as the target a shifted version of the input sequence. The code below looks a lot like the code used for training previous models with only small modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tqdm as tqdmx\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# tqdmx.tqdm.get_lock().locks = []\n",
    "\n",
    "def train_rnn_model(model, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the actual training call, notice how unlike previous experiments we are using here RMSprop which is a different type of optimizer that is often preferred for recurrent neural networks, although others such as SGD, and ADAM will also work. Additionally we are using nn.NLLLoss for the loss function, which is equivalent to the nn.CrossEntropyLoss function used before. The only difference is that nn.CrossEntropyLoss does the log_softmax operation for us, however in our implementation, we already applied log_softmax to the outputs of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabularySize = len(trainData.vocabulary['word2id'])\n",
    "model = TextGeneratorModel(vocabularySize)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
    "\n",
    "# Train the previously defined model.\n",
    "# train_rnn_model(model, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = True)\n",
    "\n",
    "# Done below in Prob 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Questions (10pts)\n",
    "<span><b>1.</b></span> (2pts) What is the number of parameters of the TextGeneratorModel? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5003, 300])\n",
      "torch.Size([512, 300])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([5003, 512])\n",
      "torch.Size([5003])\n"
     ]
    }
   ],
   "source": [
    "# Show how did you come up with that number here.\n",
    "for param in model.parameters():\n",
    "    print(param.size())\n",
    "# 5003x300 is the vocab -> embedding\n",
    "# 512x300 is W_hx\n",
    "# 512x512 is W_hh\n",
    "# the two 512s are the bias terms for W_hx and W_hh\n",
    "# 5003x512 is the linear classifier\n",
    "# 5003 is the bias term for the linear classifier\n",
    "\n",
    "# So in total there are 4,484,207 parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span><b>2.</b></span> (4pts) Provide an implementation for the function train_rnn_model from section 3, this will be similar to the train_model function used in the previous lab. Then train the model and report a few sentences generated by your model. Use the following figure as reference to make sure you are using the right inputs and targets to train the model. The loss function between predictions and targets should be nn.CrossEntropyLoss(), so you might need to collapse the batch and sequence-length dimensions before passing them to the loss function.\n",
    "\n",
    "<img src=\"rnn.png\" width=\"80%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_rnn_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (imgIds, paddedSeqs, seqLengths)) in enumerate(t):\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            initialHiddenState = Variable(torch.Tensor(1, paddedSeqs.size(1), 512).zero_())\n",
    "            if use_gpu: initialHiddenState = initialHiddenState.cuda()\n",
    "            \n",
    "            # Handle initialization\n",
    "            inputs = Variable(paddedSeqs)[:-1]\n",
    "            if use_gpu: inputs = inputs.cuda()\n",
    "            labels = Variable(paddedSeqs)[1:]\n",
    "            if use_gpu: labels = labels.cuda()\n",
    "             \n",
    "            # Forward pass:\n",
    "            outputs, _ = model(inputs, initialHiddenState)\n",
    "            outputs = outputs.view(-1, 5003)\n",
    "            labels = labels.contiguous().view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0) * len(seqLengths)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (imgIds, paddedSeqs, seqLengths)) in enumerate(t):\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            initialHiddenState = Variable(torch.Tensor(1, paddedSeqs.size(1), 512).zero_())\n",
    "            if use_gpu: initialHiddenState = initialHiddenState.cuda()\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(paddedSeqs)[:-1]\n",
    "            if use_gpu: inputs = inputs.cuda()\n",
    "            labels = Variable(paddedSeqs)[1:]\n",
    "            if use_gpu: labels = labels.cuda()\n",
    "            \n",
    "            # Forward pass:\n",
    "            outputs, _ = model(inputs, initialHiddenState)\n",
    "            outputs = outputs.view(-1, 5003)\n",
    "            labels = labels.contiguous().view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0) * len(seqLengths)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)  \n",
    "            \n",
    "# Train the previously defined model.\n",
    "train_rnn_model(model, criterion, optimizer, trainLoader, valLoader, n_epochs = 2, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implement train_rnn_model and then train the model using this function. \n",
    "# Show here a couple of sentences sampled from your model.\n",
    "print(sample_sentence(model, use_cuda = True))\n",
    "print(sample_sentence(model, use_cuda = True))\n",
    "print(sample_sentence(model, use_cuda = True))\n",
    "print(sample_sentence(model, use_cuda = True))\n",
    "print(sample_sentence(model, use_cuda = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span><b>3. </b></span> (4pts) Create an ImageCaptioningModel class here that predicts a sentence given an input image. This should be an implementation of the model in this paper https://arxiv.org/pdf/1411.4555.pdf (See figure 3 in the paper). This model is very similar to the one implemented in this lab except that the first RNN cell gets the output of a CNN as its input. I'm also illustrating it below using a figure similar to the one in the previous question. For the CNN use Resnet-18. Note: You do not need to train this model, only define it. Feel free to start from the code for the TextGeneratorModel. <img src=\"im2text.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet = models.resnet18(pretrained = True)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageCaptioningModel(nn.Module):\n",
    "    # The model has three layers: \n",
    "    #    1. An Embedding layer that turns a sequence of word ids into \n",
    "    #       a sequence of vectors of fixed size: embeddingSize.\n",
    "    #    2. An RNN layer that turns the sequence of embedding vectors into \n",
    "    #       a sequence of hiddenStates.\n",
    "    #    3. A classification layer that turns a sequence of hidden states into a \n",
    "    #       sequence of softmax outputs.\n",
    "    def __init__(self, vocabularySize):\n",
    "        super(ImageCaptioningModel, self).__init__()\n",
    "        # See documentation for nn.Embedding here:\n",
    "        # http://pytorch.org/docs/master/nn.html#torch.nn.Embedding\n",
    "\n",
    "        # remove last fully-connected layer of ResNet\n",
    "        self.new_classifier = nn.Sequential(*list(resnet.children()))\n",
    "        self.embedder2 = nn.Embedding(1000, vocabularySize) # 512 because that's the output size of Resnet's FC\n",
    "        \n",
    "        self.embedder = nn.Embedding(vocabularySize, 300)\n",
    "        self.rnn = nn.RNN(300, 512, batch_first = False)\n",
    "        self.classifier = nn.Linear(512, vocabularySize)\n",
    "        self.vocabularySize = vocabularySize\n",
    "\n",
    "    # The forward pass makes the sequences go through the three layers defined above.\n",
    "    def forward(self, paddedSeqs, initialHiddenState, image):        \n",
    "        batchSequenceLength = paddedSeqs.size(0)  # 0-dim is sequence-length-dim.\n",
    "        batchSize = paddedSeqs.size(1)  # 1-dim is batch dimension.\n",
    "        \n",
    "        # Transform the image into the output of Resnet's last FC layer\n",
    "        deepFeatRep = self.new_classifier(image)\n",
    "        \n",
    "        # And embed such that you get up to the Vocab size\n",
    "        inputValue = self.embedder2(deepFeatRep)\n",
    "        \n",
    "        # Put the output of the FC at the front of the captions\n",
    "        completePaddedSeq = Torch.cat(inputValue, paddedSeqs)\n",
    "        \n",
    "        # Transform word ids into an embedding vector.\n",
    "        embeddingVectors = self.embedder(completePaddedSeq)\n",
    "        \n",
    "        # Pass the sequence of word embeddings to the RNN.\n",
    "        rnnOutput, finalHiddenState = self.rnn(embeddingVectors, initialHiddenState)\n",
    "        \n",
    "        # Collapse the batch and sequence-length dimensions in order to use nn.Linear.\n",
    "        flatSeqOutput = rnnOutput.view(-1, 512)\n",
    "        predictions = self.classifier(flatSeqOutput)\n",
    "        \n",
    "        # Expand back the batch and sequence-length dimensions and return. \n",
    "        return predictions.view(batchSequenceLength + 1, batchSize, self.vocabularySize), \\\n",
    "               finalHiddenState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Questions (8pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span><b>1. </b></span> (1pts) What is the number of parameters of the ImageCaptioningModel from Q3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64, 64, 3, 3])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 256, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 256, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([1000, 512])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000, 5003])\n",
      "torch.Size([5003, 300])\n",
      "torch.Size([512, 300])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([5003, 512])\n",
      "torch.Size([5003])\n"
     ]
    }
   ],
   "source": [
    "model = ImageCaptioningModel(vocabularySize)\n",
    "\n",
    "# Show how did you come up with that number here.\n",
    "for param in model.parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span><b>2. </b></span> (3pts) Modify the TextGeneratorModel to use an LSTM instead, and retrain the model. Report results using this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are input and output size tensor sizes:\n",
      "('inputs', torch.Size([26, 128]))\n",
      "('outputs', torch.Size([26, 128, 5003]))\n"
     ]
    }
   ],
   "source": [
    "# By now, we should know that pytorch has a functional implementation (as opposed to class version)\n",
    "# of many common layers, which is especially useful for layers that do not have any parameters.\n",
    "# e.g. relu, sigmoid, softmax, etc.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextGeneratorModelLSTM(nn.Module):\n",
    "    # The model has three layers: \n",
    "    #    1. An Embedding layer that turns a sequence of word ids into \n",
    "    #       a sequence of vectors of fixed size: embeddingSize.\n",
    "    #    2. An RNN layer that turns the sequence of embedding vectors into \n",
    "    #       a sequence of hiddenStates.\n",
    "    #    3. A classification layer that turns a sequence of hidden states into a \n",
    "    #       sequence of softmax outputs.\n",
    "    def __init__(self, vocabularySize):\n",
    "        super(TextGeneratorModelLSTM, self).__init__()\n",
    "        # See documentation for nn.Embedding here:\n",
    "        # http://pytorch.org/docs/master/nn.html#torch.nn.Embedding\n",
    "        self.embedder = nn.Embedding(vocabularySize, 300)\n",
    "        self.rnn = nn.LSTM(300, 512, batch_first = False)\n",
    "        self.classifier = nn.Linear(512, vocabularySize)\n",
    "        self.vocabularySize = vocabularySize\n",
    "\n",
    "    # The forward pass makes the sequences go through the three layers defined above.\n",
    "    def forward(self, paddedSeqs, (initialHiddenState, initialCellState)):\n",
    "        batchSequenceLength = paddedSeqs.size(0)  # 0-dim is sequence-length-dim.\n",
    "        batchSize = paddedSeqs.size(1)  # 1-dim is batch dimension.\n",
    "        \n",
    "        # Transform word ids into an embedding vector.\n",
    "        embeddingVectors = self.embedder(paddedSeqs)\n",
    "        \n",
    "        # Pass the sequence of word embeddings to the RNN.\n",
    "        rnnOutput, (finalHiddenState, finalCellState) = self.rnn(embeddingVectors, (initialHiddenState, initialCellState))\n",
    "        \n",
    "        # Collapse the batch and sequence-length dimensions in order to use nn.Linear.\n",
    "        flatSeqOutput = rnnOutput.view(-1, 512)\n",
    "        predictions = self.classifier(flatSeqOutput)\n",
    "        \n",
    "        # Expand back the batch and sequence-length dimensions and return. \n",
    "        return predictions.view(batchSequenceLength, batchSize, self.vocabularySize), \\\n",
    "               (finalHiddenState, finalCellState)\n",
    "\n",
    "# Let's test the model on some input batch.\n",
    "vocabularySize = len(trainData.vocabulary['word2id'])\n",
    "model = TextGeneratorModelLSTM(vocabularySize)\n",
    "\n",
    "# Create the initial hidden state for the RNN.\n",
    "index, (imgIds, paddedSeqs, seqLengths) = next(enumerate(trainLoader))\n",
    "# h1  --  all 0's\n",
    "initialHiddenState = Variable(torch.Tensor(1, paddedSeqs.size(1), 512).zero_())\n",
    "initialCellState = Variable(torch.Tensor(1, paddedSeqs.size(1), 512).zero_())\n",
    "predictions, _ = model(torch.autograd.Variable(paddedSeqs), (initialHiddenState, initialCellState))\n",
    "\n",
    "print('Here are input and output size tensor sizes:')\n",
    "# Inputs are seqLength x batchSize x 1 \n",
    "print('inputs', paddedSeqs.size()) # 10 input sequences.\n",
    "# Outputs are trainData.vocabularyseqLength x batchSize x vocabularySize\n",
    "print('outputs', predictions.size()) # 10 output softmax predictions over our vocabularySize outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.LongTensor\u001b[0m), but expected (torch.FloatTensor source, int dim, torch.LongTensor index)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a8cea71bfc42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Train the previously defined model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mtrain_rnn_model_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-a8cea71bfc42>\u001b[0m in \u001b[0;36mtrain_rnn_model_lstm\u001b[0;34m(network, criterion, optimizer, trainLoader, valLoader, n_epochs, use_gpu)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Forward pass:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minitialHiddenState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialCellState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rohanbapat2891/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ba10527719cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, paddedSeqs, (initialHiddenState, initialCellState))\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Transform word ids into an embedding vector.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0membeddingVectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddedSeqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Pass the sequence of word embeddings to the RNN.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rohanbapat2891/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rohanbapat2891/anaconda2/lib/python2.7/site-packages/torch/nn/modules/sparse.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rohanbapat2891/anaconda2/lib/python2.7/site-packages/torch/nn/_functions/thnn/sparse.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.LongTensor\u001b[0m), but expected (torch.FloatTensor source, int dim, torch.LongTensor index)"
     ]
    }
   ],
   "source": [
    "def train_rnn_model_lstm(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (imgIds, paddedSeqs, seqLengths)) in enumerate(t):\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            initialHiddenState = Variable(torch.Tensor(1, paddedSeqs.size(1), 512).zero_())\n",
    "            if use_gpu: initialHiddenState = initialHiddenState.cuda()\n",
    "            initialCellState = Variable(torch.Tensor(1, paddedSeqs.size(1), 512).zero_())\n",
    "            if use_gpu: initialCellState = initialCellState.cuda()\n",
    "            \n",
    "            # Handle initialization\n",
    "            inputs = Variable(paddedSeqs)[:-1]\n",
    "            if use_gpu: inputs = inputs.cuda()\n",
    "            labels = Variable(paddedSeqs)[1:]\n",
    "            if use_gpu: labels = labels.cuda()\n",
    "             \n",
    "            # Forward pass:\n",
    "            outputs, _ = model(inputs, (initialHiddenState, initialCellState))\n",
    "            outputs = outputs.view(-1, 5003)\n",
    "            labels = labels.contiguous().view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0) * len(seqLengths)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (imgIds, paddedSeqs, seqLengths)) in enumerate(t):\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            initialHiddenState = Variable(torch.Tensor(1, paddedSeqs.size(1), 512).zero_())\n",
    "            if use_gpu: initialHiddenState = initialHiddenState.cuda()\n",
    "            initialCellState = Variable(torch.Tensor(1, paddedSeqs.size(1), 512).zero_())\n",
    "            if use_gpu: initialCellState = initialCellState.cuda()\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(paddedSeqs)[:-1]\n",
    "            if use_gpu: inputs = inputs.cuda()\n",
    "            labels = Variable(paddedSeqs)[1:]\n",
    "            if use_gpu: labels = labels.cuda()\n",
    "            \n",
    "            # Forward pass:\n",
    "            outputs, _ = model(inputs, (initialHiddenState, initialCellState))\n",
    "            outputs = outputs.view(-1, 5003)\n",
    "            labels = labels.contiguous().view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0) * len(seqLengths)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)  \n",
    "            \n",
    "vocabularySize = len(trainData.vocabulary['word2id'])\n",
    "modelLSTM = TextGeneratorModelLSTM(vocabularySize)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
    "\n",
    "# Train the previously defined model.\n",
    "train_rnn_model_lstm(modelLSTM, criterion, optimizer, trainLoader, valLoader, n_epochs = 2, use_gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelLSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-86f5ebb288ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sentence_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'modelLSTM' is not defined"
     ]
    }
   ],
   "source": [
    "def sample_sentence_lstm(model, use_cuda = False):\n",
    "    counter = 0\n",
    "    limit = 200\n",
    "    words = list()\n",
    "\n",
    "    # Setup initial input state, and input word (we use \"the\").\n",
    "    previousWord = torch.LongTensor(1, 1).fill_(trainData.vocabulary['word2id']['the'])\n",
    "    previousHiddenState = torch.autograd.Variable(torch.Tensor(1, 1, 512).zero_())\n",
    "    previousCellState = torch.autograd.Variable(torch.Tensor(1, 1, 512).zero_())\n",
    "    if use_cuda: previousHiddenState = previousHiddenState.cuda()\n",
    "    if use_cuda: previousCellState = previousCellState.cuda()\n",
    "\n",
    "    while True:\n",
    "        # Predict the next word based on the previous hidden state and previous word.\n",
    "        inputWord = torch.autograd.Variable(previousWord)\n",
    "        if use_cuda: inputWord = inputWord.cuda()\n",
    "        predictions, (hiddenState, cellState) = model(inputWord, (previousHiddenState, previousCellState))\n",
    "        nextWordId = np.random.multinomial(1, F.softmax(predictions.squeeze()).data.cpu().numpy(), 1).argmax()\n",
    "        words.append(trainData.vocabulary['id2word'][nextWordId])\n",
    "        # Setup the inputs for the next round.\n",
    "        previousWord.fill_(nextWordId)\n",
    "        previousHiddenState = hiddenState\n",
    "        previousCellState = cellState\n",
    "\n",
    "        # Keep adding words until the [END] token is generated.\n",
    "        if nextWordId == trainData.vocabulary['word2id']['[END]'] or counter > limit:\n",
    "            break\n",
    "        counter += 1\n",
    "    \n",
    "    words.insert(0, 'the')\n",
    "    words.insert(0, '[START]')\n",
    "    return string.join(words, \" \")\n",
    "\n",
    "print(sample_sentence_lstm(modelLSTM, use_cuda = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 2 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-549680c0c74f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-5e3b61605d94>\u001b[0m in \u001b[0;36msample_sentence\u001b[0;34m(model, use_cuda)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0minputWord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreviousWord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputWord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputWord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddenState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputWord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreviousHiddenState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreviousCellState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mnextWordId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id2word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnextWordId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 2 values to unpack"
     ]
    }
   ],
   "source": [
    "print(sample_sentence(modelLSTM, use_cuda = False))\n",
    "print(sample_sentence(modelLSTM, use_cuda = True))\n",
    "print(sample_sentence(modelLSTM, use_cuda = True))\n",
    "print(sample_sentence(modelLSTM, use_cuda = True))\n",
    "print(sample_sentence(modelLSTM, use_cuda = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span><b>3. </b></span> (4pts) In this question, you will have to reconstruct an input image from its activations. I will not provide you with the image, only the activation values obtained for a certain layer. You will have access to the code that was used to compute these activations. You will have to use back-propagation to reconstruct the input image. Show the reconstructed input image and tell us who is in the picture. Note: Look at the content reconstruction from outputs performed in https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Gatys_Image_Style_Transfer_CVPR_2016_paper.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.vgg16(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('image.size()', torch.Size([1, 3, 224, 224]))\n",
      "('layer-19-output.size()', torch.Size([1, 512, 28, 28]))\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "preprocessFn = transforms.Compose([transforms.Scale(256), \n",
    "                                   transforms.CenterCrop(224), \n",
    "                                   transforms.ToTensor(), \n",
    "                                   transforms.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                                                        std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "def model_F(input, kOutput = 19):\n",
    "    prev_input = input\n",
    "    for layer_id in range(0, kOutput + 1):\n",
    "        current_input = model.features[layer_id](prev_input)\n",
    "        prev_input = current_input\n",
    "    return current_input\n",
    "\n",
    "# Read the incognito image. (Obviously this is not provided in the Lab assignment.)\n",
    "image = preprocessFn(Image.open('incognito.jpg').convert('RGB'))\n",
    "image = Variable(image.unsqueeze(0))\n",
    "\n",
    "# Obtain the output of the VGG layer 19.\n",
    "model.eval()\n",
    "target = Variable(model_F(image).data) # Repack variable.\n",
    "\n",
    "print('image.size()', image.size())\n",
    "print('layer-19-output.size()', target.size())\n",
    "torch.save(target.data, open('layer-19-output.p', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def imshow(img):\n",
    "    # convert torch tensor to PIL image and then show image inline.\n",
    "    img = transforms.ToPILImage()(img[0].cpu() * 0.5 + 0.5) # denormalize tensor before convert\n",
    "    plt.imshow(img, aspect = None)\n",
    "    plt.axis('off')\n",
    "    plt.gcf().set_size_inches(4, 4)\n",
    "    plt.show()\n",
    "\n",
    "target = torch.load(open('layer-19-output.p'))\n",
    "print(target.size())\n",
    "\n",
    "# Your solution goes here. Show the reconstructed input and tell us who is depicted in the incognito.jpg image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:0.8em;color:#888;text-align:center;padding-top:20px;\">If you find any errors or omissions in this material please contact me at vicente@virginia.edu</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "2e1d0253ea4548c69171b6734b7cd099": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "b394439d588c4724a32487ececed5938": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "f9cbb62874ac4ef180e8dae925ddf8ae": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
